{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: extracting dialogs and explicit speakers from raw text (deterministic method) => done in Preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'only_utterance_article': 'My dear Mr_Bennet, [X] have you heard that Netherfield Park is let at last?',\n",
       " 'only_utterance_us': 'My dear Mr_Bennet, [X] have you heard that Netherfield Park is let at last?',\n",
       " 'parts': [{'text': 'My dear Mr_Bennet,', 'utterance': True},\n",
       "  {'speaker_function': 'lady',\n",
       "   'speaker_gender': 'F',\n",
       "   'speaker_name': None,\n",
       "   'text': ' said his lady to him one day, ',\n",
       "   'utterance': False},\n",
       "  {'text': 'have you heard that Netherfield Park is let at last?',\n",
       "   'utterance': True}],\n",
       " 'source': \"``My dear Mr_Bennet,'' said his lady to him one day, ``have you heard that Netherfield Park is let at last?''\",\n",
       " 'target': 'Mrs_Bennet'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from src.character import characters\n",
    "\n",
    "with open(\"corpus/dataset.pkl\", 'rb') as file:\n",
    "    annotated_lines = pickle.load(file)\n",
    "    \n",
    "annotated_lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"character_freq\", \n",
    "            \"character_previous_mention\",\n",
    "            \"character_dialog_mention\",\n",
    "            \"character_vocal_mention\",\n",
    "            \"character_narrator_mention\",\n",
    "            \"gender_as_supposed\",\n",
    "            \"character_spoke_last\",\n",
    "            \"character_spoke_before_last\",\n",
    "            \"character_is_target\",\n",
    "            \"character_last_target\",\n",
    "            \"character_already_spoke\"]\n",
    "\n",
    "columns = [\"dialog\", \"speaker\"] + [feature + \"_\" + character.name for feature in features for character in characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [character.name for character in characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import traceback, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def split_words(text):\n",
    "    \"remove all punctuation and split by spaces\"\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    return text.translate(table) .split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dialogs = open(\"./corpus/curated_dialogs.txt\", \"r\").read().split('\\n')[:-1]\n",
    "dataset = pd.DataFrame([], columns=columns)\n",
    "\n",
    "dialog_index = 0\n",
    "line_idx = 0\n",
    "last_speaker = \"\"\n",
    "before_last_speaker = \"\"\n",
    "last_target = \"\"\n",
    "previous_mentions = set()\n",
    "for count, (phrase, annotated_line) in enumerate(zip(dialogs, annotated_lines)):\n",
    "    try:\n",
    "        dialog, speaker, text = phrase.split(\"\\t\")\n",
    "\n",
    "        if int(dialog) > dialog_index:\n",
    "            character_dialog_mentions = {name: False for name in names}\n",
    "            spokers = set()\n",
    "            last_speaker = \"\"\n",
    "            before_last_speaker = \"\"\n",
    "            last_target = \"\"\n",
    "            dialog_index = int(dialog)\n",
    "            previous_mentions = set()\n",
    "        \n",
    "        line = {\"dialog\": int(dialog), \"speaker\": speaker}\n",
    "        previous_mentions = vocal_mentions\n",
    "        vocal_mentions = set(names).intersection(set(split_words(text)))\n",
    "        \n",
    "        words = set([word for part in annotated_line['parts'] for word in\n",
    "                     split_words(part['text']) if not part['utterance']])\n",
    "        narrator_mentions = set(names).intersection(words)\n",
    "            \n",
    "        for idx, character in enumerate(characters):\n",
    "            line[\"character_already_spoke_\" + character.name] = character.name in spokers\n",
    "            line[\"character_freq_\" + character.name] = 0.0\n",
    "            \n",
    "            line[\"character_previous_mention_\" + character.name] = character.name in previous_mentions\n",
    "            line[\"character_vocal_mention_\" + character.name] = character.name in vocal_mentions\n",
    "            line[\"character_narrator_mention_\" + character.name] = character.name in narrator_mentions\n",
    "            line[\"character_dialog_mention_\" + character.name] = character_dialog_mentions[character.name]\n",
    "                \n",
    "            character_dialog_mentions[character.name] = character_dialog_mentions[character.name] or\\\n",
    "                                                        character.name in vocal_mentions          or\\\n",
    "                                                        character.name in narrator_mentions\n",
    "            supposed_gender = None\n",
    "            for part in annotated_line[\"parts\"]:\n",
    "                if(\"speaker_gender\" in part and part[\"speaker_gender\"] is not None):\n",
    "                    supposed_gender = part[\"speaker_gender\"]\n",
    "            \n",
    "            if(supposed_gender is None):\n",
    "                gender_as_supposed = 0.5\n",
    "            elif(supposed_gender == character.gender):\n",
    "                gender_as_supposed = 1\n",
    "            else:\n",
    "                gender_as_supposed = 0\n",
    "            line[\"gender_as_supposed_\" + character.name] = gender_as_supposed\n",
    "                \n",
    "            line[\"character_last_target_\" + character.name] = True if last_target == character.name else False\n",
    "            line[\"character_spoke_last_\" + character.name] = True if last_speaker == character.name else False\n",
    "            line[\"character_spoke_before_last_\" + character.name] = True if before_last_speaker == character.name else False\n",
    "            \n",
    "            if(annotated_line[\"target\"] is not None and annotated_line[\"target\"] == character.name):\n",
    "                character_is_target = True\n",
    "            else:\n",
    "                character_is_target = False\n",
    "            line[\"character_is_target_\" + character.name] = character_is_target\n",
    "        \n",
    "        spokers.add(speaker)\n",
    "        before_last_speaker = last_speaker\n",
    "        last_speaker = speaker\n",
    "        dataset.loc[line_idx] = line\n",
    "        line_idx += 1\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exception(None, # <- type(e) by docs, but ignored \n",
    "                                     e, e.__traceback__),\n",
    "          file=sys.stderr, flush=True)\n",
    "        print(\"line {}, caused a problem: {}\".format(count, e))\n",
    "dataset[\"dialog\"] = dataset.dialog.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>speaker</th>\n",
       "      <th>character_freq_Mrs_Annesley</th>\n",
       "      <th>character_freq_Elizabeth_Bennet</th>\n",
       "      <th>character_freq_Jane_Bennet</th>\n",
       "      <th>character_freq_Lydia_Bennet</th>\n",
       "      <th>character_freq_Kitty_Bennet</th>\n",
       "      <th>character_freq_Mary_Bennet</th>\n",
       "      <th>character_freq_Mrs_Bennet</th>\n",
       "      <th>character_freq_Caroline_Bingley</th>\n",
       "      <th>...</th>\n",
       "      <th>character_already_spoke_Mr_Jones</th>\n",
       "      <th>character_already_spoke_Mr_Hurst</th>\n",
       "      <th>character_already_spoke_Mr_Morris</th>\n",
       "      <th>character_already_spoke_Mr_Philips</th>\n",
       "      <th>character_already_spoke_Mr_Pratt</th>\n",
       "      <th>character_already_spoke_Mr_Robinson</th>\n",
       "      <th>character_already_spoke_Mr_Stone</th>\n",
       "      <th>character_already_spoke_Old_Mr_Wickham</th>\n",
       "      <th>character_already_spoke_Sir_William</th>\n",
       "      <th>character_already_spoke_Mr_Wickham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mrs_Bennet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mrs_Bennet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Mrs_Bennet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr_Bennet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Mrs_Bennet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog     speaker  character_freq_Mrs_Annesley  \\\n",
       "0       1  Mrs_Bennet                          0.0   \n",
       "1       1  Mrs_Bennet                          0.0   \n",
       "2       1  Mrs_Bennet                          0.0   \n",
       "3       1   Mr_Bennet                          0.0   \n",
       "4       1  Mrs_Bennet                          0.0   \n",
       "\n",
       "   character_freq_Elizabeth_Bennet  character_freq_Jane_Bennet  \\\n",
       "0                              0.0                         0.0   \n",
       "1                              0.0                         0.0   \n",
       "2                              0.0                         0.0   \n",
       "3                              0.0                         0.0   \n",
       "4                              0.0                         0.0   \n",
       "\n",
       "   character_freq_Lydia_Bennet  character_freq_Kitty_Bennet  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   character_freq_Mary_Bennet  character_freq_Mrs_Bennet  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   character_freq_Caroline_Bingley                 ...                  \\\n",
       "0                              0.0                 ...                   \n",
       "1                              0.0                 ...                   \n",
       "2                              0.0                 ...                   \n",
       "3                              0.0                 ...                   \n",
       "4                              0.0                 ...                   \n",
       "\n",
       "   character_already_spoke_Mr_Jones  character_already_spoke_Mr_Hurst  \\\n",
       "0                             False                             False   \n",
       "1                             False                             False   \n",
       "2                             False                             False   \n",
       "3                             False                             False   \n",
       "4                             False                             False   \n",
       "\n",
       "   character_already_spoke_Mr_Morris  character_already_spoke_Mr_Philips  \\\n",
       "0                              False                               False   \n",
       "1                              False                               False   \n",
       "2                              False                               False   \n",
       "3                              False                               False   \n",
       "4                              False                               False   \n",
       "\n",
       "   character_already_spoke_Mr_Pratt  character_already_spoke_Mr_Robinson  \\\n",
       "0                             False                                False   \n",
       "1                             False                                False   \n",
       "2                             False                                False   \n",
       "3                             False                                False   \n",
       "4                             False                                False   \n",
       "\n",
       "   character_already_spoke_Mr_Stone  character_already_spoke_Old_Mr_Wickham  \\\n",
       "0                             False                                   False   \n",
       "1                             False                                   False   \n",
       "2                             False                                   False   \n",
       "3                             False                                   False   \n",
       "4                             False                                   False   \n",
       "\n",
       "   character_already_spoke_Sir_William  character_already_spoke_Mr_Wickham  \n",
       "0                                False                               False  \n",
       "1                                False                               False  \n",
       "2                                False                               False  \n",
       "3                                False                               False  \n",
       "4                                False                               False  \n",
       "\n",
       "[5 rows x 574 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train Valid Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(9295)\n",
    "dialogs = np.arange(dataset.dialog.max())\n",
    "np.random.shuffle(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set contains 48 dialogs.\n",
      "Valid set contains 6 dialogs.\n",
      "Test set contains 7 dialogs.\n"
     ]
    }
   ],
   "source": [
    "b1 = len(dialogs) * 8 // 10\n",
    "b2 = len(dialogs) * 9 // 10\n",
    "train_dialogs = dialogs[:b1]\n",
    "valid_dialogs = dialogs[b1:b2]\n",
    "test_dialogs  = dialogs[b2:]\n",
    "print(\"Train set contains {} dialogs.\".format(len(train_dialogs)))\n",
    "print(\"Valid set contains {} dialogs.\".format(len(valid_dialogs)))\n",
    "print(\"Test set contains {} dialogs.\".format(len(test_dialogs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset[dataset.dialog.isin(train_dialogs)]\n",
    "valid_dataset = dataset[dataset.dialog.isin(valid_dialogs)]\n",
    "test_dataset  = dataset[dataset.dialog.isin(test_dialogs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute the frequencies based on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "for name in names:\n",
    "    freq = len(train_dataset[train_dataset[\"speaker\"] == name]) / len(train_dataset.index)\n",
    "    train_dataset[\"character_freq_\" + name] = freq\n",
    "    valid_dataset[\"character_freq_\" + name] = freq\n",
    "    test_dataset[\"character_freq_\" + name]  = freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(learning_rate=0.02, n_estimators=500, subsample=0.95, min_samples_split=2,\n",
    "                                min_samples_leaf=2, max_depth=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_dataset.speaker.values\n",
    "X = train_dataset.drop([\"dialog\", \"speaker\"], axis=1).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        2807.1687          26.4646           44.53s\n",
      "         2        2502.4773          15.3370           44.19s\n",
      "         3        2281.2072          11.9679           45.43s\n",
      "         4        2102.6851           9.5275           46.81s\n",
      "         5        1953.7560           7.9367           48.34s\n",
      "         6        1825.9792           6.8071           50.77s\n",
      "         7        1713.3813           5.7712           52.01s\n",
      "         8        1612.4555           5.2153           53.12s\n",
      "         9        1524.7259           4.8053           54.15s\n",
      "        10        1441.2118           4.1829           54.81s\n",
      "        11        1369.2039           3.9792           55.49s\n",
      "        12        1297.0401           3.4490           55.98s\n",
      "        13        1237.1015           3.3175           56.55s\n",
      "        14        1179.1204           3.1400           57.05s\n",
      "        15        1124.3536           2.8732           57.61s\n",
      "        16        1073.0878           2.7394           58.64s\n",
      "        17        1025.2522           2.5633           59.03s\n",
      "        18         980.0684           2.3680           59.36s\n",
      "        19         937.5869           2.2601           59.56s\n",
      "        20         894.4346           2.0628           59.71s\n",
      "        21         859.3829           2.0215            1.00m\n",
      "        22         823.0945           1.8791            1.00m\n",
      "        23         789.1394           1.8186            1.00m\n",
      "        24         756.7249           1.7187            1.01m\n",
      "        25         723.4177           1.5903            1.01m\n",
      "        26         696.1306           1.5323            1.01m\n",
      "        27         668.5651           1.4556            1.01m\n",
      "        28         641.8810           1.4092            1.01m\n",
      "        29         611.9420           1.3112            1.01m\n",
      "        30         592.3267           1.2928            1.01m\n",
      "        31         566.7330           1.1890            1.01m\n",
      "        32         546.9414           1.1755            1.01m\n",
      "        33         525.7094           1.0811            1.01m\n",
      "        34         505.6000           1.0768            1.01m\n",
      "        35         486.1442           1.0253            1.01m\n",
      "        36         467.5798           0.9841            1.01m\n",
      "        37         446.7596           0.9234            1.01m\n",
      "        38         432.6044           0.9028            1.01m\n",
      "        39         416.0168           0.8510            1.01m\n",
      "        40         400.0866           0.8074            1.01m\n",
      "        41         382.5854           0.7785            1.00m\n",
      "        42         370.8021           0.7640            1.00m\n",
      "        43         355.6374           0.7198            1.01m\n",
      "        44         343.7478           0.7025            1.01m\n",
      "        45         331.0006           0.6764            1.01m\n",
      "        46         318.7247           0.6483            1.01m\n",
      "        47         305.7241           0.6038            1.01m\n",
      "        48         295.6112           0.5962            1.01m\n",
      "        49         284.6606           0.5706            1.01m\n",
      "        50         274.2466           0.5494            1.01m\n",
      "        51         263.0785           0.5094            1.01m\n",
      "        52         251.9062           0.4963            1.01m\n",
      "        53         244.6730           0.4655            1.00m\n",
      "        54         234.7878           0.4493            1.01m\n",
      "        55         227.7326           0.4504            1.01m\n",
      "        56         218.2691           0.4216            1.01m\n",
      "        57         211.5373           0.4150            1.00m\n",
      "        58         203.9310           0.4009            1.00m\n",
      "        59         196.5381           0.3837            1.00m\n",
      "        60         189.0960           0.3530            1.00m\n",
      "        61         181.6702           0.3409            1.00m\n",
      "        62         173.5855           0.3317            1.00m\n",
      "        63         169.8882           0.3291            1.00m\n",
      "        64         160.9065           0.2988           59.95s\n",
      "        65         157.9834           0.3020           59.88s\n",
      "        66         152.2024           0.2870           59.81s\n",
      "        67         146.9618           0.2805           59.75s\n",
      "        68         141.7141           0.2702           59.69s\n",
      "        69         136.6210           0.2580           59.74s\n",
      "        70         131.4585           0.2418           59.79s\n",
      "        71         127.2311           0.2393           59.91s\n",
      "        72         120.7686           0.2289           59.84s\n",
      "        73         117.7860           0.2177           59.75s\n",
      "        74         114.2148           0.2134           59.64s\n",
      "        75         108.9614           0.1958           59.54s\n",
      "        76         106.2170           0.1953           59.45s\n",
      "        77         100.8493           0.1890           59.31s\n",
      "        78          96.0403           0.1663           59.25s\n",
      "        79          93.8566           0.1665           59.17s\n",
      "        80          89.9046           0.1609           59.02s\n",
      "        81          87.4477           0.1617           58.97s\n",
      "        82          86.1469           0.1560           58.87s\n",
      "        83          83.0973           0.1501           58.75s\n",
      "        84          80.3159           0.1435           58.70s\n",
      "        85          77.4981           0.1323           58.62s\n",
      "        86          72.4448           0.1289           58.51s\n",
      "        87          72.3930           0.1292           58.39s\n",
      "        88          69.9382           0.1238           58.28s\n",
      "        89          65.2628           0.1105           58.18s\n",
      "        90          65.2934           0.1149           58.10s\n",
      "        91          63.0285           0.1109           58.04s\n",
      "        92          60.9616           0.1065           57.94s\n",
      "        93          58.9462           0.1019           57.83s\n",
      "        94          56.8935           0.0981           57.71s\n",
      "        95          55.0029           0.0949           57.58s\n",
      "        96          53.1742           0.0911           57.46s\n",
      "        97          51.2602           0.0853           57.39s\n",
      "        98          49.6470           0.0845           57.39s\n",
      "        99          47.9088           0.0803           57.34s\n",
      "       100          46.4339           0.0776           57.20s\n",
      "       101          44.9375           0.0748           57.07s\n",
      "       102          43.2276           0.0684           56.96s\n",
      "       103          42.0109           0.0694           56.83s\n",
      "       104          40.6596           0.0667           56.71s\n",
      "       105          39.3540           0.0646           56.58s\n",
      "       106          37.0234           0.0611           56.43s\n",
      "       107          35.1474           0.0592           56.26s\n",
      "       108          35.6088           0.0572           56.20s\n",
      "       109          33.1386           0.0560           56.14s\n",
      "       110          33.3960           0.0529           56.07s\n",
      "       111          30.4020           0.0396           56.05s\n",
      "       112          31.2952           0.0481           55.98s\n",
      "       113          30.3223           0.0459           55.90s\n",
      "       114          29.3878           0.0453           55.84s\n",
      "       115          28.2976           0.0422           55.72s\n",
      "       116          27.5420           0.0425           55.63s\n",
      "       117          25.8892           0.0402           55.46s\n",
      "       118          25.5778           0.0374           55.31s\n",
      "       119          25.0798           0.0376           55.15s\n",
      "       120          24.2263           0.0351           54.97s\n",
      "       121          23.5584           0.0337           54.81s\n",
      "       122          22.8252           0.0338           54.64s\n",
      "       123          22.1189           0.0328           54.51s\n",
      "       124          21.4140           0.0297           54.42s\n",
      "       125          20.7991           0.0302           54.28s\n",
      "       126          20.1719           0.0280           54.13s\n",
      "       127          19.6065           0.0279           54.02s\n",
      "       128          19.0291           0.0256           53.92s\n",
      "       129          16.7106           0.0105           53.78s\n",
      "       130          17.8786           0.0253           53.64s\n",
      "       131          17.3393           0.0227           53.48s\n",
      "       132          16.8568           0.0233           53.32s\n",
      "       133          16.4058           0.0213           53.20s\n",
      "       134          15.9100           0.0217           53.06s\n",
      "       135          15.4599           0.0206           52.92s\n",
      "       136          14.1069           0.0210           52.76s\n",
      "       137          14.6369           0.0189           52.67s\n",
      "       138          14.2287           0.0182           52.54s\n",
      "       139          13.8198           0.0180           52.36s\n",
      "       140          12.9410           0.0174           52.16s\n",
      "       141          13.0548           0.0166           51.96s\n",
      "       142          12.7156           0.0161           51.77s\n",
      "       143          12.3887           0.0146           51.56s\n",
      "       144          11.5562           0.0147           51.34s\n",
      "       145          11.7010           0.0135           51.13s\n",
      "       146          11.3661           0.0133           50.93s\n",
      "       147          11.1204           0.0130           50.74s\n",
      "       148          10.7547           0.0120           50.57s\n",
      "       149          10.5293           0.0125           50.39s\n",
      "       150           8.6961          -0.0074           50.19s\n",
      "       151           9.9973           0.0114           49.98s\n",
      "       152           9.7401           0.0109           49.77s\n",
      "       153           9.5008           0.0106           49.60s\n",
      "       154           9.1079           0.0101           49.40s\n",
      "       155           8.9521           0.0096           49.19s\n",
      "       156           8.3761           0.0095           48.98s\n",
      "       157           8.6178           0.0087           48.77s\n",
      "       158           7.6683           0.0079           48.56s\n",
      "       159           6.6781          -0.0131           48.36s\n",
      "       160           7.9750           0.0078           48.14s\n",
      "       161           7.8391           0.0077           47.94s\n",
      "       162           7.6500           0.0075           47.74s\n",
      "       163           7.4429           0.0070           47.54s\n",
      "       164           7.3026           0.0070           47.34s\n",
      "       165           7.1264           0.0065           47.14s\n",
      "       166           6.9744           0.0064           46.94s\n",
      "       167           5.3366          -0.0165           46.77s\n",
      "       168           6.6985           0.0058           46.57s\n",
      "       169           6.5323           0.0058           46.38s\n",
      "       170           6.3201           0.0047           46.20s\n",
      "       171           5.6260           0.0021           46.02s\n",
      "       172           4.0524           0.0015           45.84s\n",
      "       173           6.0139           0.0050           45.65s\n",
      "       174           5.7394           0.0041           45.45s\n",
      "       175           5.7690           0.0047           45.26s\n",
      "       176           5.6506           0.0046           45.07s\n",
      "       177           5.5363           0.0044           44.88s\n",
      "       178           5.4199           0.0042           44.70s\n",
      "       179           5.3281           0.0041           44.51s\n",
      "       180           5.2181           0.0038           44.32s\n",
      "       181           5.1307           0.0035           44.14s\n",
      "       182           5.0462           0.0037           43.95s\n",
      "       183           4.9549           0.0035           43.77s\n",
      "       184           4.8624           0.0032           43.61s\n",
      "       185           4.7692           0.0031           43.44s\n",
      "       186           4.6901           0.0032           43.25s\n",
      "       187           4.6082           0.0032           43.08s\n",
      "       188           3.1362          -0.0240           42.91s\n",
      "       189           4.4597           0.0029           42.74s\n",
      "       190           4.4043           0.0026           42.56s\n",
      "       191           4.3215           0.0027           42.38s\n",
      "       192           4.2017           0.0022           42.20s\n",
      "       193           4.1456           0.0020           42.04s\n",
      "       194           4.1374           0.0022           41.87s\n",
      "       195           4.0613           0.0023           41.70s\n",
      "       196           3.9931           0.0020           41.55s\n",
      "       197           3.9419           0.0022           41.38s\n",
      "       198           3.3688          -0.0039           41.15s\n",
      "       199           3.8144           0.0021           40.96s\n",
      "       200           3.7787           0.0017           40.76s\n",
      "       201           3.2169          -0.0042           40.53s\n",
      "       202           3.6822           0.0018           40.31s\n",
      "       203           3.6463           0.0016           40.10s\n",
      "       204           3.0744          -0.0046           39.85s\n",
      "       205           3.4466           0.0008           39.62s\n",
      "       206           3.4982           0.0015           39.39s\n",
      "       207           3.4724           0.0012           39.17s\n",
      "       208           3.3347           0.0009           38.94s\n",
      "       209           3.4000           0.0013           38.71s\n",
      "       210           3.3611           0.0011           38.48s\n",
      "       211           3.3344           0.0010           38.25s\n",
      "       212           3.2941           0.0008           38.03s\n",
      "       213           3.2556           0.0010           37.80s\n",
      "       214           2.1673          -0.0554           37.54s\n",
      "       215           1.9956          -0.0305           37.30s\n",
      "       216           3.1843           0.0009           37.07s\n",
      "       217           3.1621           0.0010           36.85s\n",
      "       218           3.1387           0.0007           36.62s\n",
      "       219           3.1143           0.0007           36.40s\n",
      "       220           3.0958           0.0008           36.19s\n",
      "       221           3.0733           0.0007           35.97s\n",
      "       222           3.0613           0.0005           35.75s\n",
      "       223           3.0424           0.0005           35.53s\n",
      "       224           3.0283           0.0004           35.30s\n",
      "       225           3.0058           0.0003           35.07s\n",
      "       226           2.9916           0.0004           34.84s\n",
      "       227           2.9566          -0.0000           34.61s\n",
      "       228           2.9724           0.0003           34.38s\n",
      "       229           2.9558           0.0003           34.15s\n",
      "       230           2.9609           0.0002           33.92s\n",
      "       231           2.9460           0.0001           33.73s\n",
      "       232           2.9473           0.0002           33.50s\n",
      "       233           2.9337           0.0001           33.28s\n",
      "       234           2.9241           0.0002           33.05s\n",
      "       235           2.8533          -0.0008           32.83s\n",
      "       236           2.9102           0.0000           32.61s\n",
      "       237           2.8988          -0.0001           32.38s\n",
      "       238           2.8922           0.0000           32.16s\n",
      "       239           1.6454          -0.0331           31.94s\n",
      "       240           2.8316          -0.0008           31.73s\n",
      "       241           2.8594          -0.0002           31.51s\n",
      "       242           2.8838           0.0001           31.30s\n",
      "       243           2.3919          -0.0083           31.08s\n",
      "       244           2.8755           0.0001           30.87s\n",
      "       245           2.8648           0.0001           30.66s\n",
      "       246           2.8549          -0.0000           30.46s\n",
      "       247           2.8517           0.0000           30.26s\n",
      "       248           1.6002          -0.0328           30.05s\n",
      "       249           2.8429           0.0000           29.85s\n",
      "       250           2.8444           0.0000           29.65s\n",
      "       251           2.8312          -0.0001           29.45s\n",
      "       252           2.3617          -0.0086           29.25s\n",
      "       253           1.5644          -0.0329           29.05s\n",
      "       254           2.8164          -0.0001           28.86s\n",
      "       255           2.8166           0.0001           28.66s\n",
      "       256           2.8132           0.0000           28.47s\n",
      "       257           2.8130           0.0001           28.28s\n",
      "       258           2.8114           0.0001           28.08s\n",
      "       259           2.8070           0.0000           27.90s\n",
      "       260           2.7901          -0.0001           27.71s\n",
      "       261           2.8022           0.0000           27.53s\n",
      "       262           2.7896          -0.0001           27.34s\n",
      "       263           2.7904           0.0001           27.16s\n",
      "       264           2.7744          -0.0002           26.98s\n",
      "       265           2.7871           0.0000           26.79s\n",
      "       266           2.7829           0.0000           26.61s\n",
      "       267           2.7604          -0.0002           26.43s\n",
      "       268           2.7541          -0.0003           26.24s\n",
      "       269           2.7684           0.0000           26.06s\n",
      "       270           2.2886          -0.0087           25.88s\n",
      "       271           2.7656           0.0001           25.71s\n",
      "       272           2.7638           0.0000           25.53s\n",
      "       273           2.7603           0.0000           25.36s\n",
      "       274           2.7583           0.0000           25.18s\n",
      "       275           2.7626           0.0000           25.01s\n",
      "       276           2.7558           0.0000           24.84s\n",
      "       277           2.7433          -0.0000           24.67s\n",
      "       278           2.7460           0.0000           24.50s\n",
      "       279           2.7449           0.0000           24.33s\n",
      "       280           2.6956          -0.0008           24.16s\n",
      "       281           2.7445           0.0000           23.99s\n",
      "       282           2.2609          -0.0085           23.83s\n",
      "       283           2.7315           0.0000           23.66s\n",
      "       284           2.7364           0.0001           23.49s\n",
      "       285           2.2343          -0.0084           23.33s\n",
      "       286           2.6667          -0.0011           23.16s\n",
      "       287           2.7004           0.0000           23.00s\n",
      "       288           2.7129          -0.0000           22.84s\n",
      "       289           2.7134          -0.0001           22.68s\n",
      "       290           2.6669          -0.0006           22.52s\n",
      "       291           2.7073          -0.0001           22.36s\n",
      "       292           2.7008          -0.0001           22.20s\n",
      "       293           2.7094           0.0000           22.05s\n",
      "       294           2.6850          -0.0003           21.89s\n",
      "       295           2.7032           0.0001           21.74s\n",
      "       296           2.6824          -0.0002           21.58s\n",
      "       297           2.6940          -0.0000           21.43s\n",
      "       298           2.6977           0.0000           21.28s\n",
      "       299           2.6861          -0.0001           21.12s\n",
      "       300           2.6877          -0.0001           20.97s\n",
      "       301           2.2014          -0.0083           20.82s\n",
      "       302           2.6841           0.0000           20.67s\n",
      "       303           2.1861          -0.0081           20.52s\n",
      "       304           2.6744          -0.0001           20.37s\n",
      "       305           2.6679          -0.0002           20.23s\n",
      "       306           2.6318          -0.0006           20.08s\n",
      "       307           2.6735           0.0001           19.94s\n",
      "       308           2.6650          -0.0001           19.79s\n",
      "       309           2.6711           0.0000           19.65s\n",
      "       310           2.6699          -0.0000           19.51s\n",
      "       311           2.1703          -0.0081           19.36s\n",
      "       312           2.1574          -0.0079           19.22s\n",
      "       313           2.6687          -0.0000           19.09s\n",
      "       314           2.6592          -0.0000           18.95s\n",
      "       315           2.6593          -0.0000           18.81s\n",
      "       316           2.6513           0.0000           18.67s\n",
      "       317           2.1549          -0.0078           18.53s\n",
      "       318           2.6493          -0.0001           18.39s\n",
      "       319           2.6041          -0.0006           18.25s\n",
      "       320           2.6526           0.0000           18.12s\n",
      "       321           2.5855          -0.0007           17.98s\n",
      "       322           2.6435          -0.0000           17.85s\n",
      "       323           2.6442           0.0000           17.71s\n",
      "       324           2.5908          -0.0008           17.58s\n",
      "       325           2.6380          -0.0000           17.44s\n",
      "       326           2.6242          -0.0002           17.31s\n",
      "       327           2.6293          -0.0001           17.18s\n",
      "       328           2.6265          -0.0002           17.05s\n",
      "       329           2.6258          -0.0001           16.92s\n",
      "       330           2.6224          -0.0001           16.79s\n",
      "       331           2.1357          -0.0080           16.66s\n",
      "       332           2.6287          -0.0000           16.53s\n",
      "       333           2.6316          -0.0000           16.40s\n",
      "       334           2.5848          -0.0006           16.27s\n",
      "       335           2.6278          -0.0000           16.14s\n",
      "       336           2.6126          -0.0002           16.02s\n",
      "       337           2.6286           0.0000           15.89s\n",
      "       338           2.6196           0.0000           15.76s\n",
      "       339           2.6163          -0.0000           15.64s\n",
      "       340           2.6178          -0.0000           15.51s\n",
      "       341           2.6042          -0.0001           15.39s\n",
      "       342           2.6000          -0.0001           15.27s\n",
      "       343           2.6026          -0.0001           15.14s\n",
      "       344           2.5871          -0.0004           15.02s\n",
      "       345           2.6061           0.0000           14.90s\n",
      "       346           2.6080          -0.0001           14.77s\n",
      "       347           2.5961          -0.0002           14.65s\n",
      "       348           2.5978          -0.0001           14.53s\n",
      "       349           2.6010           0.0000           14.41s\n",
      "       350           2.5898          -0.0001           14.29s\n",
      "       351           2.5867          -0.0002           14.17s\n",
      "       352           2.5939          -0.0000           14.05s\n",
      "       353           2.1092          -0.0083           13.93s\n",
      "       354           2.1018          -0.0081           13.81s\n",
      "       355           2.5903          -0.0000           13.69s\n",
      "       356           2.5907          -0.0000           13.57s\n",
      "       357           1.4314          -0.0337           13.45s\n",
      "       358           2.5894          -0.0000           13.34s\n",
      "       359           2.5899          -0.0000           13.22s\n",
      "       360           2.5801          -0.0000           13.11s\n",
      "       361           2.5800          -0.0001           12.99s\n",
      "       362           2.5886          -0.0000           12.87s\n",
      "       363           2.5782          -0.0000           12.76s\n",
      "       364           2.5776          -0.0001           12.65s\n",
      "       365           2.5676          -0.0002           12.53s\n",
      "       366           2.5794          -0.0000           12.42s\n",
      "       367           2.0848          -0.0087           12.31s\n",
      "       368           2.5724          -0.0000           12.19s\n",
      "       369           2.5614          -0.0003           12.08s\n",
      "       370           2.5699          -0.0001           11.97s\n",
      "       371           2.5757          -0.0000           11.86s\n",
      "       372           2.5703          -0.0000           11.74s\n",
      "       373           2.5256          -0.0006           11.63s\n",
      "       374           2.0786          -0.0087           11.52s\n",
      "       375           2.0841          -0.0081           11.41s\n",
      "       376           2.5622          -0.0002           11.30s\n",
      "       377           2.5727          -0.0000           11.19s\n",
      "       378           1.4123          -0.0338           11.08s\n",
      "       379           2.5636          -0.0000           10.97s\n",
      "       380           2.5198          -0.0008           10.86s\n",
      "       381           2.5646          -0.0000           10.76s\n",
      "       382           2.5551          -0.0001           10.65s\n",
      "       383           2.5619          -0.0000           10.54s\n",
      "       384           2.5551          -0.0000           10.43s\n",
      "       385           2.5609          -0.0000           10.33s\n",
      "       386           2.5557          -0.0000           10.22s\n",
      "       387           2.5602          -0.0000           10.12s\n",
      "       388           2.5560          -0.0000           10.01s\n",
      "       389           2.5526          -0.0001            9.91s\n",
      "       390           1.3605          -0.0337            9.80s\n",
      "       391           2.5599           0.0000            9.70s\n",
      "       392           2.5460          -0.0001            9.60s\n",
      "       393           2.5402          -0.0002            9.49s\n",
      "       394           2.5517          -0.0000            9.39s\n",
      "       395           2.5386          -0.0001            9.29s\n",
      "       396           2.5440          -0.0001            9.18s\n",
      "       397           2.5383          -0.0002            9.08s\n",
      "       398           2.5346          -0.0001            8.98s\n",
      "       399           2.5419          -0.0001            8.88s\n",
      "       400           2.5495          -0.0000            8.78s\n",
      "       401           2.5432          -0.0000            8.68s\n",
      "       402           2.5437          -0.0000            8.58s\n",
      "       403           2.5082          -0.0004            8.48s\n",
      "       404           2.5316          -0.0002            8.39s\n",
      "       405           2.5337          -0.0002            8.29s\n",
      "       406           1.3168          -0.0341            8.19s\n",
      "       407           2.5330          -0.0001            8.09s\n",
      "       408           2.5267          -0.0001            7.99s\n",
      "       409           2.5365          -0.0000            7.89s\n",
      "       410           2.5313          -0.0001            7.79s\n",
      "       411           2.5392          -0.0000            7.69s\n",
      "       412           2.5226          -0.0001            7.60s\n",
      "       413           2.5232          -0.0002            7.50s\n",
      "       414           2.5323          -0.0000            7.40s\n",
      "       415           2.5325          -0.0000            7.30s\n",
      "       416           2.5285          -0.0000            7.21s\n",
      "       417           2.5363          -0.0000            7.11s\n",
      "       418           2.5291          -0.0000            7.02s\n",
      "       419           2.5250          -0.0000            6.92s\n",
      "       420           2.5286          -0.0000            6.83s\n",
      "       421           2.0730          -0.0091            6.73s\n",
      "       422           2.5170          -0.0001            6.64s\n",
      "       423           2.5251          -0.0000            6.54s\n",
      "       424           0.8492          -0.0163            6.45s\n",
      "       425           2.0819          -0.0092            6.36s\n",
      "       426           2.5257          -0.0000            6.26s\n",
      "       427           2.5170          -0.0002            6.17s\n",
      "       428           2.5233          -0.0000            6.08s\n",
      "       429           2.5101          -0.0002            5.98s\n",
      "       430           2.5204          -0.0000            5.89s\n",
      "       431           2.5209          -0.0001            5.80s\n",
      "       432           2.5149          -0.0000            5.71s\n",
      "       433           2.5042          -0.0001            5.62s\n",
      "       434           2.5216          -0.0000            5.52s\n",
      "       435           2.5141          -0.0001            5.43s\n",
      "       436           2.4997          -0.0001            5.34s\n",
      "       437           2.4876          -0.0005            5.25s\n",
      "       438           2.5112          -0.0001            5.16s\n",
      "       439           2.4957          -0.0003            5.07s\n",
      "       440           2.4981          -0.0002            4.98s\n",
      "       441           2.5090          -0.0000            4.89s\n",
      "       442           1.3058          -0.0338            4.80s\n",
      "       443           2.0621          -0.0094            4.71s\n",
      "       444           2.4770          -0.0005            4.62s\n",
      "       445           2.0525          -0.0093            4.53s\n",
      "       446           2.4897          -0.0004            4.44s\n",
      "       447           2.5061          -0.0001            4.36s\n",
      "       448           2.5001          -0.0000            4.27s\n",
      "       449           2.5102          -0.0000            4.18s\n",
      "       450           2.4995          -0.0000            4.09s\n",
      "       451           2.5047          -0.0000            4.01s\n",
      "       452           2.4967          -0.0001            3.92s\n",
      "       453           2.0429          -0.0088            3.83s\n",
      "       454           2.5071          -0.0000            3.75s\n",
      "       455           2.5082          -0.0000            3.66s\n",
      "       456           2.4883          -0.0001            3.58s\n",
      "       457           2.5008          -0.0001            3.49s\n",
      "       458           2.0279          -0.0088            3.40s\n",
      "       459           2.4987          -0.0000            3.32s\n",
      "       460           2.4985          -0.0000            3.23s\n",
      "       461           2.0239          -0.0085            3.15s\n",
      "       462           2.5029          -0.0000            3.06s\n",
      "       463           2.4901          -0.0002            2.98s\n",
      "       464           2.5012          -0.0000            2.89s\n",
      "       465           2.0167          -0.0083            2.81s\n",
      "       466           2.4993          -0.0000            2.73s\n",
      "       467           2.4843          -0.0001            2.64s\n",
      "       468           2.4848          -0.0002            2.56s\n",
      "       469           2.4913          -0.0002            2.47s\n",
      "       470           2.4707          -0.0004            2.39s\n",
      "       471           1.3352          -0.0345            2.31s\n",
      "       472           2.4921          -0.0001            2.23s\n",
      "       473           2.4823          -0.0002            2.14s\n",
      "       474           2.4851          -0.0001            2.06s\n",
      "       475           2.4763          -0.0002            1.98s\n",
      "       476           2.4887          -0.0000            1.90s\n",
      "       477           2.4805          -0.0001            1.82s\n",
      "       478           2.4855          -0.0000            1.74s\n",
      "       479           2.4834          -0.0001            1.65s\n",
      "       480           2.4858          -0.0000            1.57s\n",
      "       481           2.0158          -0.0087            1.49s\n",
      "       482           2.4857          -0.0000            1.41s\n",
      "       483           2.4570          -0.0004            1.33s\n",
      "       484           2.4835          -0.0000            1.25s\n",
      "       485           2.4804          -0.0000            1.17s\n",
      "       486           2.4528          -0.0004            1.09s\n",
      "       487           2.4828          -0.0000            1.01s\n",
      "       488           2.4548          -0.0004            0.93s\n",
      "       489           2.4575          -0.0004            0.86s\n",
      "       490           2.4773          -0.0000            0.78s\n",
      "       491           2.4679          -0.0001            0.70s\n",
      "       492           2.4726          -0.0001            0.62s\n",
      "       493           2.4789          -0.0000            0.54s\n",
      "       494           2.4781          -0.0000            0.46s\n",
      "       495           2.4296          -0.0008            0.39s\n",
      "       496           2.0058          -0.0087            0.31s\n",
      "       497           2.4684          -0.0001            0.23s\n",
      "       498           2.4748          -0.0000            0.15s\n",
      "       499           2.4753          -0.0000            0.08s\n",
      "       500           2.4769          -0.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.02, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=2,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=500, presort='auto', random_state=None,\n",
       "              subsample=0.95, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "truth = []\n",
    "\n",
    "dialogs_done = set()\n",
    "last_speaker = \"\"\n",
    "spokers = set()\n",
    "for idx in valid_dataset.index:\n",
    "    speaker_name = None\n",
    "    for part in annotated_lines[idx][\"parts\"]:\n",
    "        if 'speaker_name' in part and part['speaker_name'] is not None:\n",
    "            speaker_name = part['speaker_name']\n",
    "            break\n",
    "    if speaker_name is not None:\n",
    "        speaker = speaker_name\n",
    "    else:\n",
    "        line = valid_dataset.loc[idx]\n",
    "        if line.dialog not in dialogs_done:\n",
    "            spokers = set()\n",
    "            last_speaker = \"\"\n",
    "            dialogs_done.add(line.dialog)\n",
    "\n",
    "        for character in characters:\n",
    "            line[\"character_already_spoke_\" + character.name] = character.name in spokers\n",
    "            line[\"character_spoke_last_\" + character.name] = True if last_speaker == character.name else False\n",
    "\n",
    "        truth.append(speaker)\n",
    "\n",
    "        speaker = GB.predict(line.values[2:].astype(np.float32).reshape(1,-1))[0]\n",
    "    pred.append(speaker)\n",
    "    last_speaker = speaker\n",
    "    spokers.add(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 31.73%\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {:.02f}%\".format(100*sum([p == t for p, t in zip(pred, truth)]) / len(truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit mention of speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified speaker: 25.19\n",
      "correct identification: 87.73\n",
      "total precision: 22.10\n"
     ]
    }
   ],
   "source": [
    "dialogs = open(\"./corpus/curated_dialogs.txt\", \"r\").read().split('\\n')[:-1]\n",
    "found = 0\n",
    "correct = 0\n",
    "for count, (phrase, annotated_line) in enumerate(zip(dialogs, annotated_lines)):\n",
    "    dialog, speaker, text = phrase.split(\"\\t\")\n",
    "    speaker_name = None\n",
    "    for part in annotated_line[\"parts\"]:\n",
    "        if 'speaker_name' in part and part['speaker_name'] is not None:\n",
    "            speaker_name = part['speaker_name']\n",
    "            break\n",
    "    if speaker_name is not None:\n",
    "        found += 1\n",
    "        if speaker_name == speaker:\n",
    "            correct += 1\n",
    "print(\"identified speaker: {:.02f}\".format(100*found/len(dialogs)))\n",
    "print(\"correct identification: {:.02f}\".format(100*correct/found))\n",
    "print(\"total precision: {:.02f}\".format(100*correct/len(dialogs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
